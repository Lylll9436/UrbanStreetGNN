"""
å›¾è‡ªç¼–ç å™¨æ¨¡å‹å¯¹æ¯”è¯„ä¼°è„šæœ¬
å¯¹æ¯”GAEã€VGAEã€GraphMAEä¸‰ç§æ¨¡å‹çš„æ€§èƒ½
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from typing import Dict, List
from sklearn.manifold import TSNE
import seaborn as sns

from autoencoder_utils import load_config


def load_training_history(model_name: str) -> Dict:
    """
    åŠ è½½è®­ç»ƒå†å²
    
    Args:
        model_name: æ¨¡å‹åç§° ('gae', 'vgae', 'graphmae')
        
    Returns:
        è®­ç»ƒå†å²å­—å…¸
    """
    history_path = f"../data/{model_name}_training_history.npy"
    
    if not os.path.exists(history_path):
        print(f"âš ï¸  è®­ç»ƒå†å²æ–‡ä»¶ä¸å­˜åœ¨: {history_path}")
        return None
    
    history = np.load(history_path, allow_pickle=True).item()
    return history


def load_embeddings(model_name: str) -> Dict:
    """
    åŠ è½½å›¾åµŒå…¥
    
    Args:
        model_name: æ¨¡å‹åç§°
        
    Returns:
        åµŒå…¥æ•°æ®å­—å…¸
    """
    embedding_path = f"../data/{model_name}_embeddings.pt"
    
    if not os.path.exists(embedding_path):
        print(f"âš ï¸  åµŒå…¥æ–‡ä»¶ä¸å­˜åœ¨: {embedding_path}")
        return None
    
    data = torch.load(embedding_path, map_location='cpu')
    return data


def plot_comparison_metrics(histories: Dict[str, Dict], save_path: str) -> None:
    """
    ç»˜åˆ¶ä¸‰ä¸ªæ¨¡å‹çš„å¯¹æ¯”å›¾è¡¨
    
    Args:
        histories: æ¨¡å‹è®­ç»ƒå†å²å­—å…¸ {model_name: history}
        save_path: ä¿å­˜è·¯å¾„
    """
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Graph AutoEncoder Models Comparison', fontsize=16, fontweight='bold')
    
    colors = {
        'gae': '#1f77b4',
        'vgae': '#ff7f0e',
        'graphmae': '#2ca02c'
    }
    
    model_labels = {
        'gae': 'GAE',
        'vgae': 'VGAE',
        'graphmae': 'GraphMAE'
    }
    
    # 1. Train Losså¯¹æ¯”
    ax1 = axes[0, 0]
    for model_name, history in histories.items():
        if history is None:
            continue
        epochs = range(1, len(history['train_loss']) + 1)
        ax1.plot(epochs, history['train_loss'], 
                label=model_labels[model_name], 
                color=colors[model_name], linewidth=2)
    ax1.set_xlabel('Epoch', fontsize=11)
    ax1.set_ylabel('Train Loss', fontsize=11)
    ax1.set_title('Training Loss Comparison', fontsize=13)
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)
    
    # 2. Val Losså¯¹æ¯”
    ax2 = axes[0, 1]
    for model_name, history in histories.items():
        if history is None:
            continue
        epochs = range(1, len(history['val_loss']) + 1)
        ax2.plot(epochs, history['val_loss'], 
                label=model_labels[model_name], 
                color=colors[model_name], linewidth=2)
    ax2.set_xlabel('Epoch', fontsize=11)
    ax2.set_ylabel('Val Loss', fontsize=11)
    ax2.set_title('Validation Loss Comparison', fontsize=13)
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)
    
    # 3. Val Precisionå¯¹æ¯”
    ax3 = axes[0, 2]
    for model_name, history in histories.items():
        if history is None:
            continue
        epochs = range(1, len(history['val_precision']) + 1)
        ax3.plot(epochs, history['val_precision'], 
                label=model_labels[model_name], 
                color=colors[model_name], linewidth=2)
    ax3.set_xlabel('Epoch', fontsize=11)
    ax3.set_ylabel('Precision', fontsize=11)
    ax3.set_title('Validation Precision Comparison', fontsize=13)
    ax3.legend(fontsize=10)
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim([0, 1.05])
    
    # 4. Val Accuracyå¯¹æ¯”
    ax4 = axes[1, 0]
    for model_name, history in histories.items():
        if history is None:
            continue
        epochs = range(1, len(history['val_accuracy']) + 1)
        ax4.plot(epochs, history['val_accuracy'], 
                label=model_labels[model_name], 
                color=colors[model_name], linewidth=2)
    ax4.set_xlabel('Epoch', fontsize=11)
    ax4.set_ylabel('Accuracy', fontsize=11)
    ax4.set_title('Validation Accuracy Comparison', fontsize=13)
    ax4.legend(fontsize=10)
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim([0, 1.05])
    
    # 5. Val AUCå¯¹æ¯”
    ax5 = axes[1, 1]
    for model_name, history in histories.items():
        if history is None:
            continue
        epochs = range(1, len(history['val_auc']) + 1)
        ax5.plot(epochs, history['val_auc'], 
                label=model_labels[model_name], 
                color=colors[model_name], linewidth=2)
    ax5.set_xlabel('Epoch', fontsize=11)
    ax5.set_ylabel('AUC', fontsize=11)
    ax5.set_title('Validation AUC Comparison', fontsize=13)
    ax5.legend(fontsize=10)
    ax5.grid(True, alpha=0.3)
    ax5.set_ylim([0, 1.05])
    
    # 6. æœ€ç»ˆæ€§èƒ½å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾ï¼‰
    ax6 = axes[1, 2]
    metrics = ['Precision', 'Accuracy', 'AUC']
    x = np.arange(len(metrics))
    width = 0.25
    
    for i, (model_name, history) in enumerate(histories.items()):
        if history is None:
            continue
        final_scores = [
            history['val_precision'][-1],
            history['val_accuracy'][-1],
            history['val_auc'][-1]
        ]
        ax6.bar(x + i * width, final_scores, width, 
               label=model_labels[model_name], 
               color=colors[model_name])
    
    ax6.set_xlabel('Metrics', fontsize=11)
    ax6.set_ylabel('Score', fontsize=11)
    ax6.set_title('Final Performance Comparison', fontsize=13)
    ax6.set_xticks(x + width)
    ax6.set_xticklabels(metrics)
    ax6.legend(fontsize=10)
    ax6.set_ylim([0, 1.05])
    ax6.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")


def plot_embedding_comparison(embeddings: Dict[str, Dict], save_path: str) -> None:
    """
    ä½¿ç”¨t-SNEå¯è§†åŒ–ä¸åŒæ¨¡å‹çš„å›¾åµŒå…¥
    
    Args:
        embeddings: æ¨¡å‹åµŒå…¥å­—å…¸ {model_name: embedding_data}
        save_path: ä¿å­˜è·¯å¾„
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    fig.suptitle('Graph Embeddings Visualization (t-SNE)', fontsize=16, fontweight='bold')
    
    model_labels = {
        'gae': 'GAE',
        'vgae': 'VGAE',
        'graphmae': 'GraphMAE'
    }
    
    for idx, (model_name, emb_data) in enumerate(embeddings.items()):
        if emb_data is None:
            continue
        
        # è·å–åµŒå…¥
        embeddings_tensor = emb_data['embeddings']
        embeddings_np = embeddings_tensor.detach().cpu().numpy()

        if embeddings_np.size == 0 or np.allclose(embeddings_np.std(axis=0), 0):
            print(f"âš ï¸ {model_labels[model_name]} åµŒå…¥æ–¹å·®æ¥è¿‘ 0ï¼Œè·³è¿‡ t-SNE å¯è§†åŒ–")
            ax = axes[idx]
            ax.axis('off')
            ax.text(0.5, 0.5, 'åµŒå…¥æ–¹å·®â‰ˆ0ï¼Œæ— æ³•ç»˜åˆ¶', fontsize=12, ha='center', va='center')
            continue

        # t-SNEé™ç»´
        print(f"å¯¹ {model_labels[model_name]} è¿›è¡Œt-SNEé™ç»´...")
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        embeddings_2d = tsne.fit_transform(embeddings_np)

        # ç»˜åˆ¶
        ax = axes[idx]
        scatter = ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], 
                           c=range(len(embeddings_2d)), 
                           cmap='viridis', 
                           alpha=0.6, 
                           s=50)
        ax.set_title(f'{model_labels[model_name]} Embeddings', fontsize=13)
        ax.set_xlabel('t-SNE Dimension 1', fontsize=11)
        ax.set_ylabel('t-SNE Dimension 2', fontsize=11)
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax, label='Graph ID')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… åµŒå…¥å¯è§†åŒ–å·²ä¿å­˜è‡³: {save_path}")


def generate_comparison_table(histories: Dict[str, Dict]) -> pd.DataFrame:
    """
    ç”Ÿæˆæ¨¡å‹å¯¹æ¯”è¡¨æ ¼
    
    Args:
        histories: æ¨¡å‹è®­ç»ƒå†å²å­—å…¸
        
    Returns:
        å¯¹æ¯”è¡¨æ ¼DataFrame
    """
    results = []
    
    for model_name, history in histories.items():
        if history is None:
            continue
        
        result = {
            'Model': model_name.upper(),
            'Final Train Loss': f"{history['train_loss'][-1]:.4f}",
            'Final Val Loss': f"{history['val_loss'][-1]:.4f}",
            'Best Val Precision': f"{max(history['val_precision']):.4f}",
            'Best Val Accuracy': f"{max(history['val_accuracy']):.4f}",
            'Best Val AUC': f"{max(history['val_auc']):.4f}",
            'Best Val AP': f"{max(history['val_ap']):.4f}",
            'Final Val Precision': f"{history['val_precision'][-1]:.4f}",
            'Final Val Accuracy': f"{history['val_accuracy'][-1]:.4f}",
            'Final Val AUC': f"{history['val_auc'][-1]:.4f}",
        }
        results.append(result)
    
    df = pd.DataFrame(results)
    return df


def main() -> None:
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("å›¾è‡ªç¼–ç å™¨æ¨¡å‹å¯¹æ¯”è¯„ä¼°")
    print("="*60)
    
    # åŠ è½½ä¸‰ä¸ªæ¨¡å‹çš„è®­ç»ƒå†å²
    print("\nğŸ“Š åŠ è½½è®­ç»ƒå†å²...")
    histories = {
        'gae': load_training_history('gae'),
        'vgae': load_training_history('vgae'),
        'graphmae': load_training_history('graphmae')
    }
    
    # åŠ è½½å›¾åµŒå…¥
    print("\nğŸ“Š åŠ è½½å›¾åµŒå…¥...")
    embeddings = {
        'gae': load_embeddings('gae'),
        'vgae': load_embeddings('vgae'),
        'graphmae': load_embeddings('graphmae')
    }
    
    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    print("\nğŸ“‹ ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼...")
    comparison_df = generate_comparison_table(histories)
    print("\n" + "="*80)
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨")
    print("="*80)
    print(comparison_df.to_string(index=False))
    print("="*80)
    
    # ä¿å­˜è¡¨æ ¼
    table_path = "../outputs/model_comparison_table.csv"
    comparison_df.to_csv(table_path, index=False)
    print(f"\nâœ… å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜è‡³: {table_path}")
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨
    print("\nğŸ“Š ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨...")
    plot_comparison_metrics(
        histories,
        save_path="../outputs/models_comparison.png"
    )
    
    # å¯è§†åŒ–åµŒå…¥
    print("\nğŸ“Š å¯è§†åŒ–å›¾åµŒå…¥...")
    plot_embedding_comparison(
        embeddings,
        save_path="../outputs/embeddings_comparison.png"
    )
    
    print("\nâœ… è¯„ä¼°å®Œæˆï¼")
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("- ../outputs/models_comparison.png")
    print("- ../outputs/embeddings_comparison.png")
    print("- ../outputs/model_comparison_table.csv")


if __name__ == "__main__":
    main()

