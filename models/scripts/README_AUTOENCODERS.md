# å›¾è‡ªç¼–ç å™¨æ¨¡å‹ä½¿ç”¨æŒ‡å—

æœ¬ç›®å½•åŒ…å«ä¸‰ç§å›¾è‡ªç¼–ç å™¨æ¨¡å‹çš„å®Œæ•´å®ç°ï¼šGAEã€VGAE å’Œ GraphMAEã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
models/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ autoencoder_utils.py       # å…±äº«å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ gae_model.py                # GAEæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ vgae_model.py               # VGAEæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ graphmae_model.py           # GraphMAEæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ train_gae.py                # GAEè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train_vgae.py               # VGAEè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train_graphmae.py           # GraphMAEè®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ evaluate_autoencoders.py    # æ¨¡å‹å¯¹æ¯”è¯„ä¼°è„šæœ¬
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ gae_config.json             # GAEé…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ vgae_config.json            # VGAEé…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ graphmae_config.json        # GraphMAEé…ç½®æ–‡ä»¶
â”œâ”€â”€ gnn_models/                     # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
â”œâ”€â”€ data/                           # ä¿å­˜è®­ç»ƒæ•°æ®å’ŒåµŒå…¥
â””â”€â”€ outputs/                        # ä¿å­˜å¯è§†åŒ–ç»“æœ
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è®­ç»ƒå•ä¸ªæ¨¡å‹

#### GAE
```bash
cd models/scripts
python train_gae.py
```

#### VGAE
```bash
cd models/scripts
python train_vgae.py
```

#### GraphMAE
```bash
cd models/scripts
python train_graphmae.py
```

### 2. å¯¹æ¯”æ‰€æœ‰æ¨¡å‹

è®­ç»ƒå®Œæ‰€æœ‰æ¨¡å‹åï¼Œè¿è¡Œå¯¹æ¯”è¯„ä¼°ï¼š

```bash
cd models/scripts
python evaluate_autoencoders.py
```

## âš™ï¸ é…ç½®æ–‡ä»¶è¯´æ˜

æ¯ä¸ªæ¨¡å‹éƒ½æœ‰ç‹¬ç«‹çš„JSONé…ç½®æ–‡ä»¶ï¼Œå¯ä»¥è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

### æ¨¡å‹å‚æ•° (`model`)
- `node_features`: èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤2ï¼šåº¦æ•°ã€ä¸­å¿ƒæ€§ï¼‰
- `edge_features`: è¾¹ç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤3ï¼šç±»å‹ã€å®½åº¦ã€é•¿åº¦ï¼‰
- `hidden_dim`: éšè—å±‚ç»´åº¦ï¼ˆé»˜è®¤256ï¼‰
- `embedding_dim`: å›¾åµŒå…¥ç»´åº¦ï¼ˆé»˜è®¤128ï¼‰
- `num_layers`: GNNå±‚æ•°ï¼ˆé»˜è®¤3ï¼‰
- `dropout`: Dropoutç‡ï¼ˆé»˜è®¤0.2ï¼‰
- `conv_type`: å·ç§¯ç±»å‹ (`gcn`, `gat`, `sage`)

### GraphMAEé¢å¤–å‚æ•°
- `mask_ratio`: èŠ‚ç‚¹æ©ç æ¯”ä¾‹ï¼ˆé»˜è®¤0.15ï¼‰

### è®­ç»ƒå‚æ•° (`training`)
- `num_epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤100ï¼‰
- `learning_rate`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤0.001ï¼‰
- `weight_decay`: L2æ­£åˆ™åŒ–ç³»æ•°ï¼ˆé»˜è®¤1e-5ï¼‰
- `train_ratio`: è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.8ï¼‰
- `val_ratio`: éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.2ï¼‰
- `seed`: éšæœºç§å­ï¼ˆé»˜è®¤42ï¼‰

### VGAEé¢å¤–å‚æ•°
- `kl_weight`: KLæ•£åº¦æƒé‡ï¼ˆé»˜è®¤0.1ï¼‰
- `kl_annealing`: KLé€€ç«ç­–ç•¥é…ç½®

### GraphMAEé¢å¤–å‚æ•°
- `link_weight`: é“¾æ¥é¢„æµ‹æŸå¤±æƒé‡ï¼ˆé»˜è®¤0.3ï¼‰

## ğŸ“Š è¾“å‡ºè¯´æ˜

### è®­ç»ƒè¿‡ç¨‹è¾“å‡º

æ¯ä¸ªæ¨¡å‹è®­ç»ƒåä¼šç”Ÿæˆï¼š

1. **æ¨¡å‹æ–‡ä»¶**
   - `{model_name}_model.pt`: æœ€ç»ˆæ¨¡å‹æƒé‡
   - `best_{model_name}_model.pt`: æœ€ä½³éªŒè¯AUCçš„æ¨¡å‹æƒé‡

2. **å›¾åµŒå…¥**
   - `{model_name}_embeddings.pt`: æ‰€æœ‰å›¾çš„åµŒå…¥å‘é‡ `[num_graphs, embedding_dim]`

3. **è®­ç»ƒå†å²**
   - `{model_name}_training_history.npy`: è®­ç»ƒæŒ‡æ ‡è®°å½•
     - `train_loss`: è®­ç»ƒæŸå¤±
     - `val_loss`: éªŒè¯æŸå¤±
     - `val_precision`: éªŒè¯ç²¾ç¡®ç‡
     - `val_accuracy`: éªŒè¯å‡†ç¡®ç‡
     - `val_auc`: éªŒè¯AUC
     - `val_ap`: éªŒè¯å¹³å‡ç²¾åº¦

4. **å¯è§†åŒ–**
   - `{model_name}_training_curves.png`: 2Ã—2è®­ç»ƒæ›²çº¿å›¾
     - å·¦ä¸Šï¼šTrain Loss vs Val Loss
     - å³ä¸Šï¼šVal Precision
     - å·¦ä¸‹ï¼šVal Accuracy
     - å³ä¸‹ï¼šç»„åˆæŒ‡æ ‡

### å¯¹æ¯”è¯„ä¼°è¾“å‡º

è¿è¡Œ `evaluate_autoencoders.py` åç”Ÿæˆï¼š

1. **models_comparison.png**: ä¸‰ä¸ªæ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”å›¾ï¼ˆ6ä¸ªå­å›¾ï¼‰
2. **embeddings_comparison.png**: ä¸‰ä¸ªæ¨¡å‹çš„åµŒå…¥ç©ºé—´å¯è§†åŒ–ï¼ˆt-SNEï¼‰
3. **model_comparison_table.csv**: æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”è¡¨æ ¼

## ğŸ”§ è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹

### ä¿®æ”¹éšè—å±‚ç»´åº¦

ç¼–è¾‘ `config/gae_config.json`:

```json
{
  "model": {
    "hidden_dim": 512,
    "embedding_dim": 256
  }
}
```

### ä¿®æ”¹å­¦ä¹ ç‡å’Œè®­ç»ƒè½®æ•°

```json
{
  "training": {
    "num_epochs": 200,
    "learning_rate": 0.0005
  }
}
```

### å¯ç”¨VGAEçš„KLé€€ç«

```json
{
  "loss": {
    "kl_annealing": {
      "enabled": true,
      "start_weight": 0.01,
      "end_weight": 0.1,
      "anneal_epochs": 30
    }
  }
}
```

### è°ƒæ•´GraphMAEæ©ç æ¯”ä¾‹

```json
{
  "model": {
    "mask_ratio": 0.25
  }
}
```

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### é“¾æ¥é¢„æµ‹æŒ‡æ ‡

- **Precisionï¼ˆç²¾ç¡®ç‡ï¼‰**: é¢„æµ‹ä¸ºæ­£æ ·æœ¬ä¸­çœŸæ­£ä¸ºæ­£æ ·æœ¬çš„æ¯”ä¾‹
- **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**: æ‰€æœ‰é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹
- **AUCï¼ˆROCæ›²çº¿ä¸‹é¢ç§¯ï¼‰**: æ¨¡å‹åŒºåˆ†æ­£è´Ÿæ ·æœ¬çš„èƒ½åŠ›
- **APï¼ˆå¹³å‡ç²¾åº¦ï¼‰**: Precision-Recallæ›²çº¿ä¸‹é¢ç§¯

### æ¨¡å‹ç‰¹å®šæŒ‡æ ‡

**VGAE**:
- `recon_loss`: é‡å»ºæŸå¤±
- `kl_loss`: KLæ•£åº¦

**GraphMAE**:
- `feature_loss`: ç‰¹å¾é‡å»ºæŸå¤±
- `link_loss`: é“¾æ¥é¢„æµ‹æŸå¤±

## ğŸ¯ ä½¿ç”¨å›¾åµŒå…¥

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åŠ è½½å›¾åµŒå…¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼š

```python
import torch

# åŠ è½½åµŒå…¥
data = torch.load('../data/gae_embeddings.pt')
embeddings = data['embeddings']  # [num_graphs, embedding_dim]
graph_ids = data['graph_ids']

# ä½¿ç”¨åµŒå…¥è¿›è¡Œåˆ†æ
print(f"åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
print(f"å›¾ID: {graph_ids}")

# è®¡ç®—å›¾ä¹‹é—´çš„ç›¸ä¼¼åº¦
similarity = torch.mm(embeddings, embeddings.t())
```

## ğŸ” æ¨¡å‹é€‰æ‹©å»ºè®®

### GAE
- âœ… ç®€å•å¿«é€Ÿï¼Œé€‚åˆbaseline
- âœ… è®­ç»ƒç¨³å®š
- âŒ è¡¨è¾¾èƒ½åŠ›ç›¸å¯¹è¾ƒå¼±

### VGAE
- âœ… å­¦ä¹ è¿ç»­æ½œåœ¨åˆ†å¸ƒ
- âœ… å¯¹å™ªå£°é²æ£’
- âœ… é€‚åˆè¡—é“ç½‘ç»œåˆ†æ
- âš ï¸ éœ€è¦è°ƒæ•´KLæƒé‡

### GraphMAE
- âœ… æœ€æ–°SOTAæ–¹æ³•
- âœ… æ©ç é¢„è®­ç»ƒï¼Œè¡¨è¾¾èƒ½åŠ›å¼º
- âœ… ç‰¹å¾é‡å»º+é“¾æ¥é¢„æµ‹åŒä»»åŠ¡
- âš ï¸ è®­ç»ƒæ—¶é—´è¾ƒé•¿

## ğŸ› å¸¸è§é—®é¢˜

### Q: è®­ç»ƒè¿‡ç¨‹ä¸­æŸå¤±ä¸ºNaN
A: é™ä½å­¦ä¹ ç‡ï¼Œæ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦æœ‰å¼‚å¸¸å€¼

### Q: éªŒè¯æŒ‡æ ‡ä¸æå‡
A: å°è¯•è°ƒæ•´æ¨¡å‹ç»“æ„ï¼ˆå¢åŠ å±‚æ•°/ç»´åº¦ï¼‰ï¼Œæˆ–ä¿®æ”¹å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥

### Q: å†…å­˜ä¸è¶³
A: å‡å° `hidden_dim` å’Œ `embedding_dim`ï¼Œæˆ–ä½¿ç”¨GPUè®­ç»ƒ

### Q: å¦‚ä½•ä¿®æ”¹å›¾æ± åŒ–ç­–ç•¥
A: åœ¨å„æ¨¡å‹çš„ç¼–ç å™¨ä¸­ä¿®æ”¹ `global_mean_pool` å’Œ `global_max_pool` ç»„åˆæ–¹å¼

## ğŸ“ å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬ä»£ç ï¼Œè¯·å¼•ç”¨ç›¸å…³è®ºæ–‡ï¼š

**GAE/VGAE**:
```
Kipf, T. N., & Welling, M. (2016). Variational graph auto-encoders. 
NIPS Workshop on Bayesian Deep Learning.
```

**GraphMAE**:
```
Hou, Z., et al. (2022). GraphMAE: Self-Supervised Masked Graph Autoencoders.
KDD 2022.
```

## ğŸ“§ è”ç³»

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ä»£ç æ³¨é‡Šæˆ–ä¿®æ”¹é…ç½®æ–‡ä»¶è¿›è¡Œè°ƒè¯•ã€‚

